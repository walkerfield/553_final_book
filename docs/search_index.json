[["index.html", "Quantifying Effects of Beaver Dams on Brooding Greater Sage-grouse Hens Chapter 1 A Foreward: Some Background for this Project 1.1 Study Site", " Quantifying Effects of Beaver Dams on Brooding Greater Sage-grouse Hens Walker Field 2024-12-07 Chapter 1 A Foreward: Some Background for this Project The greater sage-grouse (Centrocercus urophasianus) is the largest grouse species found in North America. They are emblematic of the sagebrush steppe landscape of the western United States because their population health is closely tied to this habitat and the resources found within it. However, the greater sage-grouse has experienced drastic declines in population level in recent decades; many factors can be attributed to this decline, one of which is loss of brood-rearing habitat. These are areas typically characterized by mesic conditions, with an abundance of insect and forb species that are essential for sage-grouse chicks (aka a brood) to consume in their first couple months of life. Enter the beaver dams – an incredibly powerful tool with respect to mesic habitat restoration and conservation. Dams impound water, and this water in turn alters the surrounding habitat in numerous ways, chiefly by encouraging the growth of a higher diversity of plant species than would occur in an otherwise dam-absent area. It is important to note that these dams do not have to be built by beavers themselves; beaver dam analogs (BDAs) are man-made dams, built with the purpose to mimic the function of natural ones. The premise of this project is to explore the potential relationship that exists between brooding sage-grouse hens and habitat modified by beaver dams on the landscape. In the following chapters, we will manipulate sage-grouse GPS data and beaver dam data, and will follow code to explore the relationships that exist between them. 1.1 Study Site The research for this project takes place at Rinker Rock Creek Ranch, which is located southwest of Bellevue, Idaho. The ranch is comprised of about 10,000 acres of high-quality sagebrush steppe habitat, which supports robust populations of greater sage-grouse as well as many other species that coexist with the birds. The ranch is also home to numerous beaver dams located within its riparian areas, as well as BDAs that have been implemented over the years. Consequently, this area serves as a great system for this research project to take place in. Map of the study site, highlighted in green. Maintained roads are displayed in brown. Map is oriented with north at the top. "],["building-the-database.html", "Chapter 2 Building the Database 2.1 Database Layout 2.2 Load Necessary Packages and Initiate Database 2.3 Dams Table 2.4 Hens Table 2.5 Captures Table 2.6 GPS Data Table 2.7 Nests Table 2.8 Broods Table 2.9 Mortalities Table", " Chapter 2 Building the Database In this first chapter, we will explore the process of building an SQLite database and tables using R code, and importing data into each table. 2.1 Database Layout This is a diagram of the final database system that we will build in the following sections. There are two parent tables, Dams and Hens. The Dams table will not have any tables linked to it, and the Hens table will have five tables linked to it that contain different categories of data collected in the field. Database layout 2.2 Load Necessary Packages and Initiate Database First we have to load the necessary Rstudio packages for this chapter and build the database. It will be named “MS_grsg”, because this is my Master’s research and the greater sage-grouse is the focal species. # load package library(DBI) # load data MS_grsg &lt;- dbConnect(RSQLite::SQLite(),&quot;MS_grsg.db&quot;) 2.3 Dams Table Next, we will begin to build our tables and populate our “MS_grsg” database in SQLite. The first table that we’ll build is the Dams table. This table includes dam identification, coordinates, type, status, canopy cover, and various numeric measurements. This is a parent table, and will not have any connections to any other tables created after this (i.e. no foreign key connections). # create table dbExecute(MS_grsg, &#39;create table dams( dam_id varchar(10) not null primary key, type char(3) check (type in (&quot;NAT&quot;, &quot;BDA&quot;)), x real, y real, status char(1) check (status in (&quot;A&quot;, &quot;I&quot;, &quot;B&quot;)), canopy char(1) check (canopy in (&quot;O&quot;, &quot;S&quot;, &quot;D&quot;)), length real, width real, height real, water_table real );&#39;) # read in data dams &lt;- read.csv(&quot;../../../../MS Work/Analyses/raw_data/Dam Censusing.csv&quot;) # load data into SQL table dbWriteTable(MS_grsg, &quot;dams&quot;, dams, append = TRUE) 2.4 Hens Table This table contains only the unique hen identification, created from each GPS backpack, and the sex of the captured bird (hint: they’re all females). This is our second parent table for this entire data set. Every table created after this will be linked to this table by way of the “hen_ID” column. # create table dbExecute(MS_grsg, &#39;create table hens( hen_ID varchar(6) not null primary key, sex char(1) check(sex in (&quot;M&quot;, &quot;F&quot;)) );&#39;) # read in data hens &lt;- read.csv(&quot;../../../../MS Work/Analyses/raw_data/Hens.csv&quot;) # load data into SQL table dbWriteTable(MS_grsg, &quot;hens&quot;, hens, append = TRUE) 2.5 Captures Table Here we will create the table that contains all of the data concerning the sage-grouse captures, including PTT identification, VHF frequency, capture date, time, and coordinates, and the weight and age of the bird. This table is linked to the Hens table. # create table dbExecute(MS_grsg, &#39;create table capture( cap_event varchar(20) not null primary key, PTT_ID varchar(3), hen_ID varchar(6), VHF_Freq real, date date, time time, x real, y real, weight integer, age varchar(1) check (age in (&quot;A&quot;, &quot;Y&quot;)), foreign key (hen_ID) references hens(hen_ID) );&#39;) # read in data captures &lt;- read.csv(&quot;../../../../MS Work/Analyses/raw_data/Capture.csv&quot;) # load data into SQL table dbWriteTable(MS_grsg, &quot;capture&quot;, captures, append = TRUE) 2.6 GPS Data Table This table contains the timestamps for each hen’s hourly location fix, as well as the coordinates associated with each fix. It is linked to the Hens table. # create table dbExecute(MS_grsg, &#39;create table gps_data( timestamp varchar(50) not null primary key, hen_ID varchar(6), x real, y real, foreign key (hen_ID) references hens(hen_ID) );&#39;) # read in data path &lt;- &quot;raw_data/druid/&quot; f &lt;- list.files(path, recursive = TRUE, pattern = &quot;ArgosData&quot;) # to create a file for all the hens&#39; GPS data for entire season, in a single .csv dat &lt;- data.frame() for (i in 1:length(f)) { current_file &lt;- read.csv(paste0(path, f[i])) dat &lt;- rbind(dat, current_file)} # now to remove duplicate lines of data so that the file is continuous all_hens &lt;- dat[!duplicated(dat), ] # load data into SQL table dbWriteTable(MS_grsg, &quot;gps_data&quot;, all_hens, append = TRUE) 2.7 Nests Table Here, we are creating the table that holds all of the nest information, including coordinates, nest fate, and number of eggs. It is linked to the Hens table. # create table dbExecute(MS_grsg, &#39;create table nests( nest_ID varchar(11) not null primary key, hen_ID varchar(6), x real, y real, fate varchar(7) check (fate in (&quot;Hatched&quot;, &quot;Failed&quot;)), num_of_eggs real, foreign key (hen_ID) references hens(hen_ID) );&#39;) # read in data nests &lt;- read.csv(&quot;../../../../MS Work/Analyses/raw_data/Nests.csv&quot;) # load data into SQL table dbWriteTable(MS_grsg, &quot;nests&quot;, nests, append = TRUE) 2.8 Broods Table This table contains all of the data associated with brood surveys throughout the season. Once a successful nest hatch was confirmed, brood surveys would be initiated for that brooding hen from 5 days after hatch to 50 days, with surveys occurring at 5-day intervals. The data in this table includes date, time, brood age, coordinates, brood status, and the number of chicks found. It is linked to the Hens table. # create table dbExecute(MS_grsg, &#39;create table broods( brood_ID varchar(9) not null primary key, hen_ID varchar (6), date date, time time, observer varchar(9) check (observer in (&quot;W_Field&quot;, &quot;T_Hoffman&quot;)), DAH integer, x real, y real, brood_detected varchar(3) check (brood_detected in (&quot;Yes&quot;, &quot;No&quot;)), num_of_chicks varchar(2), foreign key (hen_ID) references hens(hen_ID) );&#39;) # read in data broods &lt;- read.csv(&quot;../../../../MS Work/Analyses/raw_data/Broods.csv&quot;) # load data into SQL table dbWriteTable(MS_grsg, &quot;broods&quot;, broods, append = TRUE) 2.9 Mortalities Table Here we will create the table that contains the unfortunate information concerning our dearly departed sage-grouse hens. The data includes the observer that found the hen, date, time, and coordinates, and the estimated day of death as well as fate of the bird (was she depredated, slipped the backpack, or is it unknown?). This table is linked to the Hens table. # create table dbExecute(MS_grsg, &#39;create table mortalities( mort_ID varchar(8) not null primary key, hen_ID varchar(6), observer varchar(9) check (observer in (&quot;W_Field&quot;, &quot;T_Hoffman&quot;)), date date, time time, x real, y real, day_of_death date, fate varchar(9) check (fate in (&quot;Mortality&quot;, &quot;Slip&quot;, &quot;Unknown&quot;)), foreign key (hen_ID) references hens(hen_ID) );&#39;) # read in data morts &lt;- read.csv(&quot;../../../../MS Work/Analyses/raw_data/Mortalities.csv&quot;) # load data into SQL table dbWriteTable(MS_grsg, &quot;mortalities&quot;, morts, append = TRUE) "],["sage-grouse-gps-data.html", "Chapter 3 Sage-grouse GPS Data 3.1 Load Packages and Data 3.2 Clean the Data 3.3 Nest (the Data, not a Sage-grouse Nest… yet) 3.4 Removing Unwanted GPS Fixes 3.5 Deleting Duplicate Rows 3.6 Removing Fast Steps 3.7 Removing Fast Roundtrips 3.8 Check Data and Export", " Chapter 3 Sage-grouse GPS Data This chapter will discuss the manipulation of sage-grouse GPS data, collected by GPS backpacks at a 1-hour interval, 24 hours a day. The purpose of the GPS data is to analyze brooding hen space-use decisions within the landscape. The code in this chapter is the longest included in this document, but it will be broken down into sections in order to improve digestibility. 3.1 Load Packages and Data First, we must load our required packages for this script, then load the necessary data into the Rstudio environment. # load packages library(tidyverse) library(janitor) library(readxl) library(dplyr) library(amt) library(sf) options(digits=10) ## combine all hen data into one csv ---- # change path to working directory: path &lt;- &quot;../../../../MS Work/Analyses/raw_data/druid/&quot; f &lt;- list.files(path, recursive = TRUE, pattern = &quot;ArgosData&quot;) # to create a file for all the hens&#39; GPS data for entire season, in a single .csv dat &lt;- data.frame() for (i in 1:length(f)) { current_file &lt;- read.csv(paste0(path, f[i])) dat &lt;- rbind(dat, current_file)} # now to remove duplicate lines of data so that the file is continuous all_hens &lt;- dat[!duplicated(dat), ] 3.2 Clean the Data Now, we will begin the long task of cleaning. It is important to note that because we’re working with 23 individual birds, at some point in this script we will have to nest each hen’s data within its own data frame. That must be done so that R recognizes each hen’s respective GPS data as an individual; otherwise, if we continued working within a single data frame, R would not recognize the GPS data as belonging to 23 individuals, even though each GPS fix is associated with the hen it belongs to. But we don’t have to worry about that yet! The initial cleaning can be done within a single data frame, because the functions we’re using don’t have to apply to each individual, but to the data set as a whole. See the section subheadings, denoted with #, for an explanation of the code being used. # to clean up names and remove unwanted columns all_hens &lt;- clean_names(all_hens) %&gt;% dplyr::select(-synchronizing_time, -transmitting_time, -altitude) # to change uuid column to &quot;hen&quot; all_hens$hen &lt;- substring(all_hens$uuid, 8, 10) all_hens &lt;- all_hens %&gt;% select(-uuid) %&gt;% relocate(&quot;hen&quot;, .before = &quot;collecting_time&quot;) # split up collecting_time column all_hens$time &lt;- substring(all_hens$collecting_time, 12, 19) all_hens$date &lt;- substring(all_hens$collecting_time, 1, 10) # to convert time from character to numeric hms(all_hens$time) all_hens &lt;- all_hens %&gt;% mutate(timestamp = ymd_hms(collecting_time, tz = &quot;UTC&quot;)) %&gt;% mutate(timestamp = with_tz(timestamp, &quot;US/Mountain&quot;)) %&gt;% select(-collecting_time) all_hens &lt;- arrange(all_hens, hen, timestamp) # to delete mid-hour GPS fix errors all_hens &lt;- all_hens %&gt;% filter(!minute(timestamp) %in% c(23, 25, 33, 38, 47, 56)) # to convert CRS from lat/long to UTMs all_hens &lt;- st_as_sf(all_hens, coords = c(&quot;longitude&quot;, &quot;latitude&quot;)) st_crs(all_hens) &lt;- st_crs(4326) all_hens &lt;- st_transform(all_hens, crs = 32611) UTMs &lt;- st_coordinates(all_hens) all_hens &lt;- all_hens %&gt;% as.data.frame() %&gt;% cbind(UTMs) %&gt;% select(-geometry) %&gt;% clean_names() # drop NA or NaN coordinates all_hens &lt;- all_hens %&gt;% filter(!is.na(x) &amp; !is.na(y)) ## time to join capture data with GPS data ---- capture &lt;- read.csv(&quot;../../../../MS Work/Analyses/raw_data/Capture.csv&quot;) capture &lt;- clean_names(capture) %&gt;% select(date, time_released, ptt_id) %&gt;% mutate(ptt_id = tolower(ptt_id)) %&gt;% mutate(release_d_t = paste(date, time_released)) %&gt;% rename(hen = ptt_id) capture &lt;- capture[-c(5, 7:9), ] capture &lt;- capture %&gt;% mutate(release_d_t = ymd_hm(release_d_t, tz = &quot;US/Mountain&quot;)) capture &lt;- capture %&gt;% select(hen, release_d_t) joined_hens &lt;- left_join(all_hens, capture) ## and now we will join mortality data ---- morts &lt;- read.csv(&quot;../../../../MS Work/Analyses/raw_data/Mortalities.csv&quot;) morts &lt;- clean_names(morts) %&gt;% select(ptt_id, estimated_date_of_death) %&gt;% mutate(ptt_id = tolower(ptt_id)) %&gt;% rename(hen = ptt_id) %&gt;% rename(est_dod = estimated_date_of_death) %&gt;% slice(-(5:20)) %&gt;% mutate(t_ = &quot;01:00&quot;) %&gt;% mutate(death_d_t = paste(est_dod, t_)) %&gt;% mutate(death_d_t = ymd_hm(death_d_t, tz = &quot;US/Mountain&quot;)) %&gt;% select(-est_dod, -t_) joined_hens &lt;- left_join(joined_hens, morts) joined_hens &lt;- joined_hens %&gt;% mutate(end_d_t = case_when( !is.na(death_d_t) ~ death_d_t, is.na(death_d_t) ~ ymd_hms(&quot;2025-12-25 01:00:00&quot;, tz = &quot;US/Mountain&quot;))) # Merry Christmas! 3.3 Nest (the Data, not a Sage-grouse Nest… yet) Now comes the all-important function nest within the tidyverse packages. First we will turn the data into a track_xyt object, so that each row is readable by amt functions. After the track, we will nest the data by the “hen” column. As previously mentioned, what this does is nest each hen’s respective GPS data within her own data frame, so that Rstudio can process the data as individuals instead of one larger group. ## create track and nest ---- hen_track &lt;- make_track(joined_hens, x, y, timestamp, all_cols = TRUE, id = hen) hen_track &lt;- hen_track %&gt;% relocate(&quot;hen&quot;, .before = &quot;x_&quot;) hen_track &lt;- hen_track %&gt;% relocate(&quot;t_&quot;, .before = &quot;x_&quot;) hen_track &lt;- hen_track %&gt;% nest(data = -hen) 3.4 Removing Unwanted GPS Fixes Now that our data is nested, we can work with amt functions that are specific to each individual. The first of these is tracked_from_to, where we will remove GPS fixes that fall into one of three categories: fixes from the backpack prior to its deployment on a hen fixes from the backpack after the hen might have slipped it off in the field fixes from the backpack after the hen has died with the backpack on The “release_d_t” column is when each hen was captured, and the “end_d_t” column is either when the backpack was slipped (that’s just one hen), when she died (three hens), or the last day of the field season (19 hens) which was set as August 1st of 2024 for this first year. Note the funny syntax in our code now, using the lapply function. This is necessary because of our nested data. In order to manipulate the nested data, the function in question has to be applied to each nested data frame individually, hence… lapply. # to remove pre-deployment / slips / post-mort fixes hen_track &lt;- hen_track %&gt;% mutate(data = lapply(data, function(x) { x %&gt;% tracked_from_to(from = x$release_d_t, to = x$end_d_t)})) hen_track &lt;- hen_track %&gt;% mutate(data=lapply(data, function(x) { x %&gt;% select(-release_d_t, -death_d_t, -end_d_t, -time, -date)})) 3.5 Deleting Duplicate Rows Satellites aren’t perfect – if they were, it’s likely that I wouldn’t have to do any of this data cleaning at all. One common issue among all satellite-collected GPS data is duplicate rows, where the satellites take multiple fixes at each interval. I’m guessing this is to account for fix accuracy, with the assumption being that if multiple fixes are taken, there will at least be one good one in the bunch. But that’s just my assumption. For my project, I am interested in how the hens are using the landscape at the hourly scale. What I’m not interested in is where she was at midnight, and then again 3 minutes later… primarily because it’s probably the exact same spot. Here we will use the flag_duplicates function, to parse the data for each hen down to only one fix per hour. Normally, this would be done using a DOP column in the data, which indicates the quality of the fix from satellites. Sadly, I do not have access to that information for my fixes, so instead I created a “fake_DOP” column and just took the first fix from every set of multiples per hour. # to delete duplicate rows hen_track &lt;- hen_track %&gt;% mutate(data = lapply(data, function(x) { x %&gt;% mutate(fake_DOP = 1)})) hen_track &lt;- hen_track %&gt;% mutate(data = lapply(data, function(x) { x %&gt;% flag_duplicates(gamma = minutes(5), DOP = &quot;fake_DOP&quot;)})) hen_track &lt;- hen_track %&gt;% mutate(data = lapply(data, function(x) { x %&gt;% filter(!duplicate_)})) hen_track &lt;- hen_track %&gt;% mutate(data = lapply(data, function(x) { x %&gt;% select(-fake_DOP, -duplicate_)})) 3.6 Removing Fast Steps Okay, so now we’re down to a data set that contains GPS data for each hen for the entire length of time that we’re interested in. However, as previously mentioned, satellites aren’t perfect. Besides collecting duplicate fixes each hour, sometimes they misgauge the location of the hen altogether (was my hen really in Antarctica on July 6th?? It’s not that hot at the ranch). This is another common occurrence, and we’ll deal with these location errors using the flag_fast_steps function. As seen in the code below, a “delta” value must be specified within the function. This is essentially a distance threshold, so that any distance greater than that traveled by the hen in an hour at that delta speed will get flagged. This is how the real fixes (from one hilltop to the next) don’t get flagged, but the error fixes (from Idaho to Antarctica) do get flagged. # to remove fast steps from satellite error ffs_2600 &lt;- hen_track %&gt;% mutate(data = lapply(data, function(x) { x %&gt;% flag_fast_steps(delta = 2600, time_unit = &quot;secs&quot;)})) hen_track &lt;- ffs_2600 %&gt;% mutate(data = lapply(data, function(x) { x %&gt;% filter(!fast_step_) %&gt;% select(-fast_step_)})) 3.7 Removing Fast Roundtrips Similar to the last function, flag_roundtrips will flag any consecutive two steps that occur outside of a specified threshold. We will use the same “delta” value, but now an “epsilon” value is included as well. I’m not gonna bother explaining the math because I don’t understand it… if you’re curious, seek out Dr. Brian Smith. The major difference between the “fast_steps” function and this “roundtrips” function is that the former only flags individual steps, while this one flags pairs of steps… hence, the roundtrip (and out-and-back movement). Note the final line of code here, dealing with hen #19. She had a very unique error step in her data set, in which it was too short to be flagged by both flag_fast_steps and flag_roundtrips, but if the “delta” value was decreased to include this particular step, then real steps from other hens were falsely getting flagged as well. Fortunately, this was the only step out of thousands that presented this issue, so the best solution was just to remove it manually. # to remove round trips from satellite error frt_5 &lt;- hen_track %&gt;% mutate(data = lapply(data, function(x) { x %&gt;% flag_roundtrips(delta = 2600, epsilon = 5)})) hen_track &lt;- frt_5 %&gt;% mutate(data = lapply(data, function(x) { x %&gt;% filter(!fast_roundtrip_) %&gt;% select(-fast_roundtrip_)})) hen_track$data[[19]] &lt;- hen_track$data[[19]][-92, ] 3.8 Check Data and Export Well, that’s it for the GPS cleaning. What we are now left with is GPS fixes for each hen, once an hour, from the time the backpack was put on them to the last relevant time this season. Each fix has coordinates and a date and time, so that we know exactly where every hen was at each hour of the time frame of interest. The final step in this chapter is to unnest the data and check to see that everything looks as it should. Once checked, the data can be exported to a processed data folder for later manipulation. # quality check all_hens_clean &lt;- unnest(hen_track, cols = data) head(all_hens_clean) ## # A tibble: 6 × 4 ## hen t_ x_ y_ ## * &lt;chr&gt; &lt;dttm&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 3bc 2024-04-28 11:01:01 712802. 4802387. ## 2 3bc 2024-04-28 12:01:20 712811. 4802368. ## 3 3bc 2024-04-28 13:01:36 712798. 4802385. ## 4 3bc 2024-04-28 14:00:47 712804. 4802389. ## 5 3bc 2024-04-28 15:01:17 712802. 4802386. ## 6 3bc 2024-04-28 16:01:06 712838. 4802350. #write.csv(all_hens_clean, file = &quot;processed_data/all_hens_clean.csv&quot;) "],["brooding-hens.html", "Chapter 4 Brooding Hens 4.1 Load Packages and Data 4.2 Nests 4.3 Non-attempts 4.4 It’s a Mama Party 4.5 Brood Data", " Chapter 4 Brooding Hens Now that we’ve got a GPS data set all cleaned up, the next step is to separate it for our hens of interest: the brooding hens, the mamas, the gals carrying the team. Since the end goal is to ultimately analyze the space-use decisions of brooding hens, this chapter is where we’ll acquire that data. The process is fairly easy, and the function to use is one we’ve seen in the previous chapter. 4.1 Load Packages and Data First, as usual, we’ll load the necessary packages and load in our data (the now clean GPS data that we created in the previous chapter). # load packages library(amt) library(tidyverse) library(dplyr) library(janitor) ## load GPS data ---- hens &lt;- read.csv(&quot;../../../../MS Work/Analyses/processed_data/all_hens_clean.csv&quot;) %&gt;% dplyr::select(-X) hens$t_ &lt;- ymd_hms(hens$t_) 4.2 Nests Next is to load in the nest database, which contains all of the information about each hen’s nest. Ultimately, the only three columns that we’re interested in are the hen identifier, the nest fate, and the estimated day of that fate. Once we load in the nest data and clean it up to our liking, we’ll join it to the hen GPS data by the “hen” column. That way, what we’ll be left with is GPS data for each hen with her nest information of interest. ## load in nest database and clean up ---- nests &lt;- read.csv(&quot;../../../../MS Work/Analyses/raw_data/Nests.csv&quot;) nests &lt;- clean_names(nests) %&gt;% select(ptt_id, nest_fate, fate_date_estimate) %&gt;% mutate(ptt_id = tolower(ptt_id)) %&gt;% rename(hen = ptt_id) nests &lt;- nests[-c(10, 17, 21), ] nests$fate_date_estimate &lt;- ymd(nests$fate_date_estimate) # alright, now let&#39;s join nests to hens hen_fate &lt;- left_join(hens, nests) 4.3 Non-attempts In an ideal world, every hen would attempt a nest and lay eggs, and they would all hatch successfully and we’d have sage-grouse around every bush. However, that doesn’t happen for a multitude of reasons, one of which is that sometimes a gal just doesn’t feel like laying eggs that year. Can’t blame her, right? So we have to drop those girls from the data set, because as important as their existence is, their space-use decisions are not of interest to us. # drop the hens that never attempted hen_fate &lt;- hen_fate %&gt;% filter(!is.na(nest_fate)) 4.4 It’s a Mama Party The next step is to pull only the brooding hens’ data from the larger data set. Thankfully, this will be easy because of our “nest_fate” column from the Nests table, which specifies whether each nest hatched or failed. Note the new name of the data set: b_hens. # successful nests only b_hens &lt;- hen_fate[hen_fate$nest_fate == &quot;Hatched&quot;, ] 4.5 Brood Data The last few lines of code in this chapter involve the brood survey data that was collected out in the field. A “Final_Broods” table is loaded in, which contains the information for each brooding hen’s final survey of the season, whether that be the 50-day mark because her and her brood survived the entire time, or some point prior to that 50 days because either the hen died or she lost her chicks. The important thing is that after we join this data to our “b_hens” data set, we will be able to further partition the brooding hen data down to the time of nest hatch to the final survey for each hen, thus giving us a complete brooding hen GPS data set that we can analyze with respect to a multitude of variables. You’ll recognize the tracked_from_to function, which is what we used in the previous chapter to initially partition the GPS data. Here, we are using it again to achieve the finalized GPS data set, where each brooding hen’s data will run from the day of nest hatch to the final survey date of the season. As usual, the last line of code is to export our manipulated data. ## load in brood data ---- broods &lt;- read.csv(&quot;../../../../MS Work/Analyses/raw_data/Final_Broods.csv&quot;) broods &lt;- broods[-c(11:17), ] broods &lt;- clean_names(broods) %&gt;% dplyr::select(ptt_id, date, scheduled_dah, brood_suspected) %&gt;% mutate(ptt_id = tolower(ptt_id)) %&gt;% rename(hen = ptt_id) %&gt;% rename(final_date = date) broods$final_date &lt;- mdy(broods$final_date) # join the two data sets b_hens &lt;- left_join(b_hens, broods) # track each hen from nest hatch to final survey b_hens &lt;- b_hens %&gt;% tracked_from_to(from = b_hens$fate_date_estimate, to = b_hens$final_date + 1) %&gt;% select(-nest_fate, -fate_date_estimate, -scheduled_dah, -final_date, -brood_suspected) #write.csv(b_hens, file = &quot;processed_data/brooding_hens.csv&quot;) "],["the-beavers.html", "Chapter 5 The Beavers 5.1 Load Packages and Data 5.2 Clean the (Dam) Data 5.3 Template 5.4 Dam Conversion 5.5 Raster Calculations", " Chapter 5 The Beavers Now we’ll switch gears and start looking at the beaver dam data. This table includes all of the data that was collected in the summer of 2024 while censusing beaver dams. See Chapter 1.3 for all of the columns included in this table.The ultimate goal of this chapter is to end up with a beaver dam data set that is cleaned up and ready to analyze, and to create some figures using that data. 5.1 Load Packages and Data As usual, we’ll first load in the necessary packages and data for this chapter. # load packages library(tidyverse) library(readxl) library(dplyr) library(lubridate) library(janitor) library(terra) options(digits=10) ## load in dam data ---- dams &lt;- read.csv(&quot;../../../../MS Work/Analyses/raw_data/Dam Censusing.csv&quot;) 5.2 Clean the (Dam) Data Next, we’ll clean up the beaver dam data a bit to make it more readable, and so that all measurements are in the metric system. # clean up the data dams &lt;- dams %&gt;% clean_names() %&gt;% select(c(2:11)) %&gt;% mutate(height_cm = height_in * 2.54) %&gt;% mutate(height_in = NULL) %&gt;% mutate(water_table_cm = water_table_in * 2.54) %&gt;% mutate(water_table_in = NULL) dams$height_cm &lt;- round(dams$height_cm, digits = 0) dams$water_table_cm &lt;- round(dams$water_table_cm, digits = 0) dams &lt;- dams[-(287:299), ] 5.3 Template Now we must create a raster template that we can crop the dam data to. As seen below, the first line is loading a “bound_box” file into the environment. This was created in a previous script not included in this document, for brevity’s sake. In short, this is a rectangular raster whose four corners are defined by the minimum and maximum X and Y coordinates from the hens’ GPS fixes. The result, then, is a boundary box that contains all of the locations of all 23 hens. This is important because any covariates included in the model (elevation, slope, etc) will then be cropped down to this box to reduce unnecessary computation. # create template raster and fit to dams bound_box &lt;- readRDS(&quot;../../../../MS Work/Analyses/processed_data/bound_box.rds&quot;) bound_box &lt;- ext(bound_box) dam_template &lt;- rast(ext = bound_box, resolution = 30, crs = &quot;epsg:32611&quot;) 5.4 Dam Conversion The next step is to convert the dam data, which is currently a data frame, into vector data (points, lines and polygons) that matches the CRS of the study site (UTM zone 11). Then, that vector data can be rasterized (converted to pixels, where each pixel has a value) and fit to the boundary box that we created in 4.3. # convert dams into vector data all_dams &lt;- vect(dams, geom = c(&quot;easting&quot;, &quot;northing&quot;), crs = &quot;epsg:32611&quot;) # rasterize dam data all_dams_raster &lt;- rasterize(all_dams, dam_template, field = 1) 5.5 Raster Calculations Now that we have the dam data in raster format and properly cropped to our area of interest, we can manipulate it for the purposes of this study. The code here is simple. The distance function computes the geographic distance from a pixel with a dam to each cell within the entire raster. Then, when this is plotted, we achieve a heat map of the area of interest with a distance associated with each 30m pixel to the closest dam. # calculate distance to dam cell values all_dis_to_dams &lt;- terra::distance(all_dams_raster) plot(all_dis_to_dams) #writeRaster(all_dis_to_dams, &quot;processed_data/all_dam_distance.tiff&quot;, overwrite = TRUE) "],["lets-plot.html", "Chapter 6 Let’s Plot! 6.1 Load Packages and Data 6.2 Visualize the Data", " Chapter 6 Let’s Plot! Finally, after endless lines of code, we are ready to visualize the data that we’ve worked so hard to clean. In this chapter, we will plot the brooding hen GPS points that we isolated from the larger data set in chapter 3. Remember, each of these GPS points was taken at a 1-hour interval from the time of nest hatch to the final brood survey date for each individual hen. These points will be plotted against the beaver dam map that was created at the end of chapter 4, which is a heat map that shows each 30m pixel’s distance to the closest measured dam (any dam status). 6.1 Load Packages and Data First, we’ll load the necessary packages and data. The star package in this chapter is ggplot2, which provides R users with very intuitive functions to aid in plotting data. Then, we must load our “distance to dam” map as well as our brooding hen data set. # load packages library(ggplot2) library(terra) library(sf) library(tidyterra) library(viridis) ## load data ---- # convert distance to dam plot to a data frame all_dist &lt;- rast(&quot;../../../../MS Work/Analyses/processed_data/all_dam_distance.tiff&quot;) %&gt;% rename(distance = last) all_dist_df &lt;- as.data.frame(all_dist, xy = TRUE) # convert brooding hen data set to sf object b_hens &lt;- read.csv(&quot;../../../../MS Work/Analyses/processed_data/brooding_hens.csv&quot;) %&gt;% dplyr::select(-X) b_hens_sf &lt;- st_as_sf(b_hens, coords = c(&quot;x_&quot;, &quot;y_&quot;), crs = 32611) 6.2 Visualize the Data And now, the final step. There are many functions within the ggplot2 package. Here I will break down all of the ones used to create these plots. geom_raster is used to plot raster data stored as a data frame. Within this function, we specify the data input and aesthetics for the data once plotted. labs allows us to adjust the labels of the plot, including the x and y axes, and a plot caption. theme lets us manipulate details about label display. geom_sf is similar to geom_raster except for plotting sf_object data. scale_fill_viridis_c is a function for assigning color scales to the displayed data. facet_wrap allows us to separate this data from one all-encompassing plot into individual plots by brooding hen. ## create plot ---- ggplot() + geom_raster(data = all_dist_df, mapping = aes(x = x, y = y, fill = distance)) + labs(x = &quot;latitude&quot;, y = &quot;longitude&quot;, caption = &quot;Representation of each hen&#39;s GPS point distances to closest dam.&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) + geom_sf(data = b_hens_sf, mapping = aes(color = hen)) + scale_fill_viridis_c() + facet_wrap(~ hen) Now we have a visual of how the brooding hens from the 2024 season were moving around the landscape with respect to beaver dam presence. There is quite a bit of variation between each hen’s movements, with some of them utilizing areas closer to beaver dams than others. The big question is – at this landscape-scale, are there underlying reasons for the hens using this specific valley as opposed to one right next door? Further data collection and analysis is needed to address that question. Thank you and please come again. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
